---
layout: word
word: markov_decision_process_(mdp)
translation: "(MDP) فرایند تصمیم گیری مارکوف "
tags:
  - word
  - M
---
[s/state/](s/state/)یک چارچوب ریاضی است برای مدل‌سازی تصمیم‌گیری در شرایطی که نتایج تا حدودی تصادفی و تا حدودی تحت کنترل یک تصمیم‌گیر است. MDPs برای مطالعه طیف گسترده‌ای از مسائل [بهینه سازی](https://fa.wikipedia.org/wiki/%D8%A8%D9%87%DB%8C%D9%86%D9%87%E2%80%8C%D8%B3%D8%A7%D8%B2%DB%8C "بهینه‌سازی") که از طریق [برنامه‌نویسی پویا](https://fa.wikipedia.org/wiki/%D8%A8%D8%B1%D9%86%D8%A7%D9%85%D9%87%E2%80%8C%D8%B1%DB%8C%D8%B2%DB%8C_%D9%BE%D9%88%DB%8C%D8%A7 "برنامه‌ریزی پویا") و [تقویت یادگیری](r/reinforcement_learning_(rl)) حل می‌شوند مفید است.

تصویر زیر یک نمونه ساده از MDP است:

![](/assets/img/20060904224736-markov_decision_process_example.png)

این نمونه دارای ۳ [حالت](s/state) (دایره های سبز رنگ) و ۲ [عمل](a/action) (a0 , a1) و ۲ [پاداش](r/reward) ( خط های نارنجی رنگ) است